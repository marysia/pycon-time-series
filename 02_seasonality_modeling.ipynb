{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"css/custom.css\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"css/custom.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import dates\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality Modeling\n",
    "![footer_logo](images/logo.png)\n",
    "\n",
    "\n",
    "## Goal\n",
    "During this session, we will learn about time series modeling. We will address: \n",
    "- What does a time series consist of?\n",
    "- What is seasonality and why is it important?\n",
    "- Ways (not) to identify seasonality\n",
    "- The power of linear models\n",
    "- Splitting time series for forecasting\n",
    "- Manual error-trend-seasonality decomposition\n",
    "- Feature engineering tricks to improve your models\n",
    "- Feature significance & importance\n",
    "- Fitting sine curve(s)\n",
    "- Forecast evaluation\n",
    "- and more!\n",
    "\n",
    "## Program\n",
    "\n",
    "1. [Dealing with Seasonality](#dws)\n",
    "2. [Linear Modeling Approach](#lma)\n",
    "3. [Feature Engineering](#fe)\n",
    "4. Gradual Seasonal Filtering\n",
    "    - [GSF](#gsf)\n",
    "    - [Advanced GSF](#agsf)\n",
    "    - [GSF Summary](#gsfsum)\n",
    "5. BONUS\n",
    "    - [Feature Significance](#fs)\n",
    "\t- [Outlier Detection](#od)\n",
    "\t- [Fitting a Sine Curve?](#sine)\n",
    "6. [Forecast Evaluation for Seasonality Models](#eval)\n",
    "7. [Summary](#sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![footer_logo](images/air-quality.jpeg) \n",
    "\n",
    "\n",
    "## The Data\n",
    "\n",
    "We will use a dataset containing daily air quality index in Californian counties between 2007 and 2017 based on a larger dataset from [Kaggle](https://www.kaggle.com/epa/carbon-monoxide). Each datapoint indicates the average air quality index on a certain day: the higher - the more polluted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_df = pd.read_csv('data/air_quality.csv', index_col='date_local', parse_dates=True)\n",
    "air_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df.plot(figsize=(18,6))\n",
    "air_df['2010-09':'2012-02'].plot(figsize=(18,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can notice some regularities over these years:\n",
    "- **Trends** (upward / horizontal / downward)\n",
    "- **Seasonality** (predictably repeating cycles - weekly/monthly/yearly etc)\n",
    "- **Cyclical components** (patterns with no set repetition - for example trend breaks or random shocks) \n",
    "- **Residuals** (the remaining part of the series that cannot be further explicitly modeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dws'></a>\n",
    "## 1. Dealing with Seasonality\n",
    "Seasonality obscures the actual signal, which complicates both understanding of the underlying processes and further forecasting. Understanding it gets us closer to what actually happens in the data ― which also means easier forecasting. Identifying and dealing with seasonality is also important for a range of other reasons. Here is a summary:\n",
    "\n",
    "- Getting closer to the actual signal\n",
    "- Understanding the nature of seasonal spikes and drops\n",
    "- Identifying plateaus and seasonality magnitude dynamics\n",
    "- Deseasonalizing data, which is required for some forecasting algorithms\n",
    "- Letting forecasting models explicitly predict seasonal effects\n",
    "- Seasonality is very typical for modern day business data\n",
    "\n",
    "One of the simplest ways to identify signal is to substantially **smooth** our time series. This can average out the effects of seasonality, but can come with its own issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    air_df\n",
    "    .assign(rolling = lambda df: df['aqi'].rolling(365, center=True).mean(),\n",
    "            #exponential=lambda df: df['aqi'].ewm(alpha=0.001).mean()\n",
    "           )\n",
    "    .plot(figsize=(18,6))\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can naively suggest that the remaining variation in the series is largely seasonality with a bit of noise, which can be in its turn smoothed out as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    air_df\n",
    "    .assign(rolling = lambda df: df['aqi'].rolling(365, center=True).mean(),\n",
    "            seasonality = lambda df: df['aqi'] - df['rolling'],\n",
    "            seasonality_smoothed = lambda df: df['seasonality'].rolling(90, center=True).mean()\n",
    "           )\n",
    "    .loc['2009':'2015']\n",
    "    #[['seasonality','seasonality_smoothed']]\n",
    "    [['seasonality_smoothed']]\n",
    "    .plot(figsize=(18,6))\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is this an adequate representation of seasonal cycles? Does it have any issues?\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lma'></a>\n",
    "## 2. Linear Modeling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to identify the main pattern(s) taking place in the data is to fit a linear regression. Even the most basic linear model with a single time component can inform us about the general trend, (mostly) leaving the seasonality aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df['time'] = np.arange(len(air_df.index))\n",
    "\n",
    "X = air_df[['time']]\n",
    "y = air_df['aqi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting a linear model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "air_df['linear_trend'] = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_df[['aqi','linear_trend']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As simple as this is, it gives us an idea of what happens over time. Of course a single linear trend cannot take dynamical changes in growth/decline rates into account. But we can still take care of this by adding break indicators & interaction terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_break = (\n",
    "    air_df\n",
    "    .assign(after2014 = [1 if el>pd.Timestamp('2014-6') else 0 for el in air_df.index],\n",
    "            interaction = lambda df: df['time']*df['after2014'])\n",
    "    [['time', 'after2014','interaction']]\n",
    ")\n",
    "\n",
    "lm_break = LinearRegression().fit(X_break, y)\n",
    "\n",
    "air_df['linear_trend_break'] = lm_break.predict(X_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "air_df[['aqi','linear_trend_break']].plot(figsize=(16,4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fe'></a>\n",
    "## 3. Feature Engineering\n",
    "\n",
    "We may want to do more than just identifying the trend though. Modeling the seasonality would allow us to understand and quantify the seasonal effects. And this means an ability to model not just the average behavior, but exact values during each season.\n",
    "\n",
    "A simple way to achieve this would be to add seasonal dummy terms to the baseline linear regression. In fact, *feature engineering* can be a very powerful tool in Time Series analysis, allowing us to capture rather complex patters with a few simple engineered variables added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying months and preprocessing them\n",
    "air_df['month']=air_df.index.month\n",
    "\n",
    "#train-test split\n",
    "air_df_train = air_df.loc[:'2015-4'].copy()\n",
    "air_df_test = air_df.loc['2015-5':].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split illustrated\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "air_df_train[['aqi']].plot(ax=ax)\n",
    "air_df_test[['aqi']].plot(ax=ax)\n",
    "plt.legend([\"train set\",\"test set\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding month indicators\n",
    "X_monthly=air_df_train[['time','month']]\n",
    "y_train = air_df_train['aqi'].values\n",
    "\n",
    "feature_transformer = ColumnTransformer(\n",
    "      [('categorical', OneHotEncoder(drop='first'), ['month'])],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "model_monthly = Pipeline([\n",
    "    ('preprocess', feature_transformer),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "lm_monthly = model_monthly.fit(X_monthly, y_train)\n",
    "print(f\"R^2 is {round(lm_monthly.score(X_monthly, y_train),3)}\")\n",
    "\n",
    "air_df['y_pred_monthly'] = lm_monthly.predict(air_df[['time','month']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* **R-squared** (coefficient of determination) is a statistical measure of how close the data are to the fitted regression line. It shows the percentage of the dependent variable variation that is explained by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_df[['aqi','y_pred_monthly']].loc[:'2015-4'].plot(figsize=(16,4), color=['#499DE6','red']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple model appears to reasonably capture the observed seasonality, even if has a number of drawbacks. This model assumes fixed monthly jumps, while the actual seasonality seems more complex than just fixed jumps or drops, but this approach already illustrates the main patterns. Moreover, it already allows us to separate seasonality from the trend and the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_season_effect = np.dot(lm_monthly['model'].coef_[:-1], [1/12]*11)\n",
    "\n",
    "simple_ets = (\n",
    "    air_df\n",
    "    [['aqi','y_pred_monthly', 'time']]\n",
    "    .loc[:'2015-4']\n",
    "    .rename(columns={\"aqi\": \"y_real\", \"y_pred_monthly\": \"y_hat\"})\n",
    "    .assign(residuals = lambda df: df['y_real']-df['y_hat'],\n",
    "            trend = lambda df: lm_monthly['model'].intercept_+lm_monthly['model'].coef_[-1]*df['time']+average_season_effect,\n",
    "            seasonal = lambda df: df['y_hat']-df['trend']\n",
    "           )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simple_ets[['y_real','y_hat','trend']].plot(figsize=(16,4))\n",
    "simple_ets[['seasonal']].plot(figsize=(16,2), c='m')\n",
    "simple_ets[['residuals']].plot(figsize=(16,2), c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having broken down a time series into its major components, we can now also *detrend* or *deseasonalize* it by subtracting the respective components. This can provide us with a clearer picture of what is going on over time aside from the trend and/or the seasonal fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ets = (simple_ets\n",
    "              .assign(deseasonalized = lambda df: df['y_real']-df['seasonal'],\n",
    "                      detrended = lambda df: df['y_real']-df['trend']))\n",
    "\n",
    "simple_ets[['deseasonalized']].plot(figsize=(16,3), c='g', label=\"deseasonalized time series\")\n",
    "simple_ets[['detrended']].plot(figsize=(16,3), c='m', label=\"detrended time series\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gsf'></a>\n",
    "## 4. Gradual Seasonal Filtering\n",
    "\n",
    "Often seasonal effects do not come just as fixed spikes or drops. They may have gradually increasing and decreasing effects as their peak approaches and moves away in time. In such cases we may want to use a neater alternative to seasonal dummies - *gradual seasonal filters*.\n",
    "\n",
    "There are a variety of such features that we could create. A simple yet effective example are linear monthly spikes:\n",
    "\n",
    "$$ \\phi(x_i) = \\max( 1 - \\frac{| x - x^*|}{n} , 0)$$\n",
    "\n",
    "where $x$ is a given data point, $x^*$ is the peak of the current filter, and $n$ is the interval of growth/decline of the spike around the peak (e.g. 30 days). In practice, a filter like this translates into a variable with values the closer to 1 (or to 0), the closer (or the further) a particular date is from the given peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsf_feature_maker(day, center_day, n=30):\n",
    "    if day - center_day >= 334:\n",
    "        day = day - 365 #ensures continuity for December-January\n",
    "    return np.fmax(-np.abs(day - center_day)/n + 1, 0)\n",
    "\n",
    "base = [gsf_feature_maker(el, 200) for el in np.arange(365)]\n",
    "plt.figure(figsize = (17,3))\n",
    "plt.plot(base);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such gradual filters could be especially handy when dealing with daily (or even hourly) data that typically exhibits more gradual seasonal effects. A separate filter can be assigned to each potential seasonal peak — each month in the example below. But really your creativity is the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = pd.date_range('2008-01-01', periods = 12, freq = 'M')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17,3))\n",
    "for month in months:\n",
    "    ax.plot([gsf_feature_maker(el, month.dayofyear) for el in np.arange(365)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_df_gsf=air_df[['aqi','time']].copy()\n",
    "air_df_gsf['month']=air_df_gsf.index.month\n",
    "air_df_gsf['dayofyear']=air_df_gsf.index.dayofyear\n",
    "\n",
    "#determining month starting days as day of the year numbers\n",
    "month_start_days=[]\n",
    "for i in range(1,13):\n",
    "    month_start_days.append(air_df_gsf.loc[lambda df: df.month==i].iloc[0]['dayofyear'])\n",
    "    \n",
    "month_start_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 12 GSF features to the dataset\n",
    "for i in range(12):\n",
    "    feature_name=\"f\"+str(i)\n",
    "    peak = month_start_days[i]\n",
    "    air_df_gsf[feature_name] = [gsf_feature_maker(date.dayofyear, peak) for date in air_df_gsf.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_df_gsf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting the new features visually\n",
    "fig, ax = plt.subplots(figsize=(17,3))\n",
    "for i in range(12):\n",
    "    feature_name=\"f\"+str(i)\n",
    "    air_df_gsf[[feature_name]].loc[:'2008'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gsf = np.c_[air_df_gsf[['time']], air_df_gsf.iloc[:,4:]]\n",
    "X_gsf_train = np.c_[air_df_gsf[['time']].loc[:'2015-4'], air_df_gsf.iloc[:,4:].loc[:'2015-4']]\n",
    "y_train = air_df_gsf['aqi'].loc[:'2015-4']\n",
    "\n",
    "lm_gsf = LinearRegression().fit(X_gsf_train, y_train)\n",
    "print(f\"R^2 is {round(lm_gsf.score(X_gsf_train, y_train),3)}\")\n",
    "\n",
    "air_df_gsf['gsf_pred'] = lm_gsf.predict(X_gsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "air_df_gsf[['aqi','gsf_pred']].loc[:'2015-4'].plot(figsize=(16,4), color=['#499DE6','red']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agsf'></a>\n",
    "### Advanced gradual seasonal filtering\n",
    "\n",
    "A more elegant alternative to linear spikes: a filter based on Gaussian distribution around the peak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_feature_values(day, center_day, year_days=365, alpha = 0.005):\n",
    "    return np.exp(-((day - center_day)**2)/2*alpha)\n",
    "\n",
    "base = [rbf_feature_values(el, 200, alpha = 0.001) for el in np.arange(365)]\n",
    "plt.figure(figsize = (17,3))\n",
    "plt.plot(base);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will however leave this as material for further self-study and self-exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradual Seasonal Filtering summary\n",
    "\n",
    "**Pros** \n",
    "\n",
    "- simple feature engineering trick\n",
    "- all variables are interpretable\n",
    "- seasonal effects can be quantified\n",
    "- focus on filtering out the long term season, other fluctuations can be modeled separately\n",
    "\n",
    "**Cons** \n",
    "\n",
    "- the model can get a bit biased \n",
    "- the model may have issues if the seasonality changes over time (fixable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fs'></a>\n",
    "## BONUS: Feature significance\n",
    "\n",
    "Another nice possibility that comes with linear seasonality modeling is statistical testing. We can distinguish features that actually help our model from useless ones. Useless features are typically an unnecessary strain on our model. Let's have a look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from regressors import stats\n",
    "\n",
    "print(\"\\n=========== SUMMARY ===========\")\n",
    "xlabels = [\"time\"] + list(air_df_gsf.iloc[:,4:-1].columns)\n",
    "stats.summary(lm_gsf, X_gsf_train, y_train, xlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like almost all features are significant except for f2. In a nutshell: we are checking if *p-values* are smaller than 0.05. Roughly speaking, a *p-value* informs us of how likely it is that we got this particular coefficient even though it should actually be zero. Therefore the lower the p-value - the more confident we are that the respective feature is an important factor in our model.\n",
    "\n",
    "We could also achieve similar conclusions if we use special types of linear regressions that only select valuable features, such as Ridge / Lasso regressions. Simply put, we can punish our model for including features that don't really improve the fit. This is a good direction for further [reading](http://www.few.vu.nl/~wvanwie/Courses/HighdimensionalDataAnalysis/WNvanWieringen_HDDA_Lecture234_RidgeRegression_20182019.pdf) and self-study!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='od'></a>\n",
    "## BONUS: Outlier detection\n",
    "\n",
    "Having a reasonable model for seasonality, we can now also use it to better understand what was happening in the past. Most notably, we can identify periods that stand out from regular seasonal patterns. This brings us to outlier detection. While there are many techniques for that, a simple natural way would be to look for data points deviating from the model more than a certain threshold percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_df_gsf['aqi'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting datapoints deviating more than 20% from the model\n",
    "outliers=[]\n",
    "\n",
    "for i in range(len(air_df_gsf)):\n",
    "    \n",
    "    if np.abs(air_df_gsf['aqi'].iloc[i]-air_df_gsf['gsf_pred'].iloc[i])/air_df_gsf['gsf_pred'].iloc[i]>0.15:\n",
    "        outliers.append(air_df_gsf['aqi'].iloc[i])\n",
    "    else:\n",
    "        outliers.append(np.nan)\n",
    "\n",
    "air_df_gsf['outliers']=outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#illustrating outliers\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "air_df_gsf[['aqi','gsf_pred']].loc[:'2012'].plot(color=['#499DE6','green'], ax=ax, alpha=0.7)\n",
    "air_df_gsf[['outliers']].loc[:'2012'].plot(color='orangered', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#2014 zoom in: droughts and wildfires\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "air_df_gsf[['aqi','gsf_pred']].loc['2014'].plot(color=['#499DE6','green'], ax=ax, alpha=0.7)\n",
    "air_df_gsf[['outliers']].loc['2014'].plot(color='orangered', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking against a certain percentage threshold may be a bit arbitrary. That's why more advanced approaches to outlier detection use confidence bounds around the model instead. The example above should nonetheless illustrate the idea of how such techniques work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sine'></a>\n",
    "## BONUS: Fitting a Sine Curve?\n",
    "\n",
    "An alternative approach to using dummies or other similar features could be fitting a predetermined function that naturally mimics the behavior of our time series. In fact our data kind of looks like sine fluctuations, doesn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "air_df_train['sine_example']=2*np.sin(0.015*air_df_train['time'])\n",
    "\n",
    "air_df_train[['aqi', 'sine_example']].plot(figsize=(18,6), color=['#499DE6','red']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how can we fit a sine curve? Can we still use linear regression?\n",
    "\n",
    "Yes!!\n",
    "\n",
    "A standard linear model fitting a sine curve over a year would have the following form:\n",
    "\n",
    "$$ y_i = w_0 + w_1 t_i + w_2 \\sin{(\\frac{2 \\pi t_i}{365} + \\Phi)} + \\varepsilon_i$$\n",
    "\n",
    "$w_2$ determines the amplitude (gap between top and bottom parts) and $\\Phi$ shifts the sine curve left/right along the *x-axis*. The problem though is that we have two parameters for a single linear component. Luckily we can use a very neat trick from Trigonometry that will help us separate the two:\n",
    "\n",
    "$$ \\sin{(a - b)} = \\sin{(a)}\\cos{(b)} - \\cos{(a)}\\sin{(b)}$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$ \\sin{(2 \\pi t_i + \\Phi)} = \\sin{(2 \\pi t_i)}\\cos{(\\Phi)} - \\cos{(2 \\pi t_i)}\\sin{(\\Phi)}$$\n",
    "\n",
    "Since $\\sin{(\\Phi)}$ and $\\cos{(\\Phi)}$ are just constants, we can then simply fit the following linear model:\n",
    "\n",
    "$$ y_i = w_0 + w_1 t_i + w_2 \\sin{(\\frac{2 \\pi t_i}{365})} + w_3 \\cos{(\\frac{2 \\pi t_i}{365})} + \\varepsilon_i$$\n",
    "\n",
    "We simply need to calculate the $\\sin$ and $\\cos$ components as new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_df = (\n",
    "    air_df[['aqi','time']]\n",
    "    .assign(sin = lambda df: np.sin(2*np.pi*df.time/365),\n",
    "            cos = lambda df: np.cos(2*np.pi*df.time/365),\n",
    "            #sin_time = lambda df: df.sin*df.time,\n",
    "            #cos_time = lambda df: df.cos*df.time\n",
    "        \n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sin = sin_df.iloc[:,1:]\n",
    "X_sin_train = X_sin.loc[:'2015-4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_sin = LinearRegression().fit(X_sin_train, y_train)\n",
    "print(f\"R^2 is {round(lm_sin.score(X_sin_train, y_train),3)}\")\n",
    "\n",
    "sin_df['aqi_pred'] = lm_sin.predict(X_sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sin_df[['aqi','aqi_pred']].loc[:'2015-4'].plot(figsize=(18,6), color=['#499DE6','red']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks quite natural, doesn't it? One problem is though that it looks like the fluctuations should shrink over time. *Think about how we can fix this.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also perform the error-trend-seasonality decomposition again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sin_df['trend'] = lm.intercept_+lm.coef_[0]*np.arange(len(air_df.index))\n",
    "sin_df['seasonal'] = sin_df['aqi_pred'] - sin_df['trend']\n",
    "sin_df['resid'] = sin_df['aqi'] - sin_df['aqi_pred']\n",
    "\n",
    "(\n",
    "    sin_df[['aqi','aqi_pred','trend', 'seasonal', 'resid']]\n",
    "    .loc[:'2015-4']\n",
    "    .plot(figsize=(18,6), legend=False, color=['#499DE6','red', 'green', 'orangered', 'slategrey'])\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sine fitting: pros/cons and next steps\n",
    "\n",
    "Fitting a sine curve can be an example of a high bias & low variance seasonality model. We have less risk of overfitting, but perhaps we oversimplify the dynamics too much. Still, it may be a good choice for models with very regular seasonal cycles or simply when we require quick deseasonalization.\n",
    "\n",
    "This example also serves as an introduction to a more advanced technique - [Fast Fourier Transform algorithm](https://ipython-books.github.io/101-analyzing-the-frequency-components-of-a-signal-with-a-fast-fourier-transform/), that relies on combining multiple sine terms for seasonality modeling. It uses the famous result by French mathematician Joseph Fourier: *a reasonably continuous and periodic function can be expressed as the sum of series of sine terms*. \n",
    "\n",
    "For now we leave this topic for your future research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <a id='eval'></a>\n",
    "## 6. Forecast Evaluation for Seasonality Models\n",
    "\n",
    "So far we focused on how well our models fit on the past data (train set). In practice we often want to also forecast for the future, and therefore we want to compare our models in their forecasting ability. Let's compare forecasts of our models on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "air_df[['aqi', 'y_pred_monthly']].loc['2015-5':].plot(color=['#499DE6','orangered'], ax=ax)\n",
    "air_df_gsf[['gsf_pred']].loc['2015-5':].plot(color=['red'], ax=ax)\n",
    "sin_df[['aqi_pred']].loc['2015-5':].plot(color=['green'], ax=ax)\n",
    "plt.ylim(0,9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our models are better at predicting winter values rather than summer values. We need to take into account however that summer of 2016 may have been unusually hot.\n",
    "\n",
    "Let's evaluate each model and see which one actually did the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = air_df['aqi'].loc['2015-5':].values\n",
    "\n",
    "def get_mape(y_true, y_pred): \n",
    "\n",
    "    return round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAPE for the dummy model is {get_mape(y_test, air_df['y_pred_monthly'].loc['2015-5':].values)}\")\n",
    "\n",
    "print(f\"MAPE for the gsf model is {get_mape(y_test, air_df_gsf[['gsf_pred']].loc['2015-5':].values)}\")\n",
    "\n",
    "print(f\"MAPE for the sinusoid model is {get_mape(y_test, sin_df[['aqi_pred']].loc['2015-5':].values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the dummy model appears to perform the best, while the gsf model - the worst. This should make us thinking and raise a few questions for the future:\n",
    "\n",
    "- Is this train-test split always adequate?\n",
    "- Luck or skill?\n",
    "- What are we punishing our models the most for?\n",
    "- Are we using an adequate metric?\n",
    "- Do we want to compare forecasts the the real noisy data or to smoothed series?\n",
    "- How far in the future we want to forecast?\n",
    "\n",
    "Those are all valid questions, but I'm afraid we would need to also spend a whole separate session to answer them... \n",
    "So for now let's say \"*To be continued...*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sum'></a>\n",
    "## 7. Summary\n",
    "\n",
    "- Seasonality matters!\n",
    "- There are many ways to identify it\n",
    "- Linear models are more powerful than people think\n",
    "- Feature engineering is a way to turn your creativity into better models\n",
    "- Sine waves are pretty\n",
    "- Online learning works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
